---
permalink: /
title: "张宸，助理教授、博导，上海交通大学"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

## 个人简介

> 我于2023年5月加入上海交通大学电子信息与电气工程学院，任长聘教轨助理教授，博士生导师，上海市海外高层次人才计划。主要研究方向是AI处理器架构和芯片系统。此前，于2017年从北京大学博士毕业，导师[丛京生教授](https://vast.cs.ucla.edu/people/faculty/jason-cong)和[孙广宇教授](https://ic.pku.edu.cn/szdw/zzjs/sjzdhyjsxtx1/sgy/index.htm)。期间于2015-2016前往美国加州大学洛杉矶分校([UCLA]((https://vast.cs.ucla.edu/people/alumni/chen-zhang)))学术访问。毕业后（2017-2023），任职微软研究院（主管研究员）和阿里巴巴平头哥半导体（架构师），参与并主导了多个国内外重要AI处理器与系统的研发工作。在 ISCA、MICRO、FPGA、DAC、T-CAD等国际会议和期刊发表论文30余篇，其中CCF(中国计算机学会)A类论文16篇，中美发明专利8项。谷歌学术统计，第一作者/通讯作者论文总引用4100余次，近5年总引用3400余次。


## Biography

> I joined the School of Electronic Information and Electrical Engineering at Shanghai Jiao Tong University in May 2023 as a Tenure-Track Assistant Professor and Ph.D. advisor. I am also a recipient of the Shanghai Overseas High-Level Talent Program. My primary research interests lie in AI processor architecture and chip systems. I received my Ph.D. from Peking University in 2017, advised by [Prof. Jason Cong](https://vast.cs.ucla.edu/people/faculty/jason-cong)and [Prof. Guangyu Sun](https://ic.pku.edu.cn/szdw/zzjs/sjzdhyjsxtx1/sgy/index.htm). During my Ph.D. studies, I was a visiting scholar at the University of California, Los Angeles (UCLA) from 2015 to 2016 (link). After graduation, I worked at Microsoft Research as a Senior Researcher and at Alibaba T-Head Semiconductor as an Architect, where I led and participated in several high-impact AI processor and system design projects. I have published over 30 papers in leading international conferences and journals, including ISCA, MICRO, FPGA, DAC, and IEEE TCAD, with 16 papers in CCF-A venues. I hold 8 invention patents in China and the U.S. According to Google Scholar, my first-author or corresponding-author publications have received over 4,100 citations in total, including more than 3,400 citations in the past five years.

Selected Publications（[Full List](https://chenzhangsjtu.github.io/publications/)）
======
- H^2-LLM: Hardware-Dataflow Co-Exploration for Heterogeneous Hybrid-Bonding-based Low-Batch LLM Inference, **ISCA**, 2025
- SynGPU: Synergizing CUDA and Bit-Serial Tensor Cores for Vision Transformer Acceleration on GPU, **DAC**, 2025
- Oltron: Software-Hardware Co-design for Outlier-Aware Quantization of LLMs with Inter-/Intra-Layer Adaptation, **DAC**, 2024
- Dual-side sparse tensor core, **ISCA**, 2021
- Caffeine: Toward uniformed representation and acceleration for deep convolutional neural networks, **T-CAD**, 2018
- Optimizing FPGA-based accelerator design for deep convolutional neural networks, **FPGA**, 2015


Awards and Honors
======
- [2025] FPGA and Reconfigurable Computing Hall of Fame (名人堂)
- [2024] Stanford and Elsevier Top-2% Most Cited Scholars (Computer Architecture and Hardware)
- [2021~2024] AI-2000 World's Most Influential Scholars (AI Chip)
- [2023] MICRO Top Picks (Honorable Mention)
- [2022] ACM ChinaSys Rising Star
- [2019] Donald O. Pederson Best Paper
- [2019] Microsoft Research Special Stock Award
- [2015] FPGA Best Paper Nomination
